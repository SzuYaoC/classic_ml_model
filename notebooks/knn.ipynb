{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a98111",
   "metadata": {},
   "source": [
    "# K-nearest Neighbors\n",
    "\n",
    "## 1. Definition\n",
    "KNN is a non-parametric, instance-based learning algorithm used for classification and regression. It predicts the label/value of a new point by finding the k closest data points in the training set and aggregating their labels. It solves the problem of modeling complex, non-linear decision boundaries without making strong assumptions about the underlying data distribution. It's a lazy learner - it doesn't build a model during training but memorizes the dataset and makes decisions only during inference.\n",
    "\n",
    "## 2. Core Idea\n",
    "KNN relies on the smoothness assumption - points that are close to each other in the feature space likely belong to the same class or have similar target values.\n",
    "Decision boundary is not extremely complex (KNN can struggle in high-dimensional spaces → curse of dimensionality).\n",
    "* **Feature Scaling is Crucial:** Since it relies on distance calculation, it implicitly assumes that all features contribute equally to the distance, which makes **feature scaling (normalization or standardization)** essential to prevent features with larger magnitudes from dominating the distance calculation.\n",
    "\n",
    "## 3. Mechanism\n",
    "The workflow is unique because there is effectively no \"training\" phase.\n",
    "* Storage: The model simply stores the entire training dataset in memory.\n",
    "* Distance Calculation: When a new query point $x_i$ arrives, KNN calculates the distance (e.g. Euclidean) between it and every other points.\n",
    "* Neighbor Retrieval: It identifies the K points with the smallest distance.\n",
    "* Voting/Averaging:\n",
    "    * Classification: KNN assigns the class that is the **most frequent** among its $k$ nearest neighbors (a majority vote).\n",
    "    * Regression: KNN predicts the value by calculating the **average** (or weighted average) of the target values of its $k$ nearest neighbors.\n",
    "\n",
    "## 4. Mathematics and Training\n",
    "* Loss function: None explicitly optimized during training\n",
    "* Distance Metrics:\n",
    "    * Euclidean ($L2$): $\\sqrt{\\sum{(x_i - y_i)^2}}$\n",
    "    * Manhattan ($L1$): $\\sum{|x_i-y_i|}$\n",
    "    * Minkowski: Generalization of L1 and L2\n",
    "* K: We use cross-validation to choose k\n",
    "\t* Small K → high variance, low bias\n",
    "\t* Large K → low variance, high bias\n",
    "\n",
    "## 5. Pros and Cons\n",
    "* Pros:\n",
    "    * Zero training time O(1)\n",
    "    * Simple & powerful: can learn very complex non-linear boundaries\n",
    "    * Adaptability: new training data can be added instantly without retraining a model\n",
    "* Cons:\n",
    "    * Slow Inference: Querying is expensive O(N) .. compare against every data point\n",
    "    * Memory Expensive\n",
    "    * Feature Scaling: It is broken by unscaled data\n",
    "    * High-dimensional data kills performance: In high dimensions (e.g., >100 features), \"distance\" becomes meaningless because all points become roughly equidistant.\n",
    "    * Imbalanced data has bias\n",
    "\n",
    "\n",
    "## 6. Production System\n",
    "Almost never used in production due to latency.\n",
    "\n",
    "\n",
    "## 7. Other Variants\n",
    "* Approximate Nearest Neighbors (ANN): These trade 1% accuracy for 1000x speedups by searching \"buckets\" of points rather than every single point.\n",
    "* Indexing: Use tree structure like KD-tree or Ball trees to speed up search from O(N) to O(log N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff32032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "root = os.path.abspath(\"..\")\n",
    "sys.path.append(root)\n",
    "\n",
    "from src.knn import KNN\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff0f61f",
   "metadata": {},
   "source": [
    "## Case 1: Recommender System\n",
    "\n",
    "* Amazon used “item-to-item similarity” (a KNN-style algorithm)\n",
    "* Google Search used KNN for early query similarity and document clustering\n",
    "* YouTube used KNN for item similarity before the “Deep Neural Recommender” era\n",
    "\n",
    "\n",
    "### Business Problem\n",
    "Amazon has millions of items but each user interacts with only a few.\n",
    "We need recommendations that are fast, scalable, personalizable, and easy to update incrementally.\n",
    "\n",
    "Classic user-based content filtering breaks when:\n",
    "* Each user has very few interactions\n",
    "* User similarities are sparse\n",
    "* The user base is huge\n",
    "\n",
    "\n",
    "### Data Problem\n",
    "We use 'item-item' KNN to resolve this issue. The goal is to build a system that:\n",
    "* Compute similarity between items\n",
    "* Retrieves the top-k similar items for any item\n",
    "* Uses these KNN results to generate user-level recommendations in milliseconds\n",
    "\n",
    "\n",
    "### Dataset\n",
    "Our dataset contains the user purchase history.\n",
    "\n",
    "\n",
    "### Feature Engineering\n",
    "* Encode user-item interactions: Each item becomes a vector: \n",
    "    - iPad -> [1,0,1,...]\n",
    "    - iPhone -> [1,1,0,...]\n",
    "* Compute KNN (item similarity): Use vector distances e.g. Cosine similarity, Jaccard, Person; \n",
    "    - For each item $i$, we store: top-k most similar items e.g. \"KNN for iPhone\" → [AirPods, iPad, Macbook]\n",
    "\n",
    "* Real-time user recommendation\n",
    "    - Look at items they interacted with\n",
    "    - Fetch precomputed item-similarity list\n",
    "    - Combine/weight scores\n",
    "    - Return top-ranked items\n",
    "This is KNN applied on items only → extremely scalable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c16e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U1</td>\n",
       "      <td>iPhone 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U1</td>\n",
       "      <td>AirPods Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U1</td>\n",
       "      <td>iPad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U2</td>\n",
       "      <td>iPhone 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U2</td>\n",
       "      <td>AirPods Pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id    item_name\n",
       "0      U1    iPhone 15\n",
       "1      U1  AirPods Pro\n",
       "2      U1         iPad\n",
       "3      U2    iPhone 15\n",
       "4      U2  AirPods Pro"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy purchase history: (user, item)\n",
    "data = [\n",
    "    (\"U1\", \"iPhone 15\"),\n",
    "    (\"U1\", \"AirPods Pro\"),\n",
    "    (\"U1\", \"iPad\"),\n",
    "\n",
    "    (\"U2\", \"iPhone 15\"),\n",
    "    (\"U2\", \"AirPods Pro\"),\n",
    "\n",
    "    (\"U3\", \"MacBook Air\"),\n",
    "    (\"U3\", \"iPhone 15\"),\n",
    "    (\"U3\", \"AirPods Pro\"),\n",
    "\n",
    "    (\"U4\", \"MacBook Air\"),\n",
    "    (\"U4\", \"iPad\"),\n",
    "\n",
    "    (\"U5\", \"Kindle Paperwhite\"),\n",
    "    (\"U5\", \"Echo Dot\"),\n",
    "\n",
    "    (\"U6\", \"Kindle Paperwhite\"),\n",
    "    (\"U6\", \"iPad\"),\n",
    "\n",
    "    (\"U7\", \"Echo Dot\"),\n",
    "    (\"U7\", \"iPhone 15\"),\n",
    "\n",
    "    (\"U8\", \"Echo Dot\"),\n",
    "    (\"U8\", \"AirPods Pro\"),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"user_id\", \"item_name\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a03f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_name</th>\n",
       "      <th>AirPods Pro</th>\n",
       "      <th>Echo Dot</th>\n",
       "      <th>Kindle Paperwhite</th>\n",
       "      <th>MacBook Air</th>\n",
       "      <th>iPad</th>\n",
       "      <th>iPhone 15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "item_name  AirPods Pro  Echo Dot  Kindle Paperwhite  MacBook Air  iPad  \\\n",
       "user_id                                                                  \n",
       "U1                 1.0       0.0                0.0          0.0   1.0   \n",
       "U2                 1.0       0.0                0.0          0.0   0.0   \n",
       "U3                 1.0       0.0                0.0          1.0   0.0   \n",
       "U4                 0.0       0.0                0.0          1.0   1.0   \n",
       "U5                 0.0       1.0                1.0          0.0   0.0   \n",
       "U6                 0.0       0.0                1.0          0.0   1.0   \n",
       "U7                 0.0       1.0                0.0          0.0   0.0   \n",
       "U8                 1.0       1.0                0.0          0.0   0.0   \n",
       "\n",
       "item_name  iPhone 15  \n",
       "user_id               \n",
       "U1               1.0  \n",
       "U2               1.0  \n",
       "U3               1.0  \n",
       "U4               0.0  \n",
       "U5               0.0  \n",
       "U6               0.0  \n",
       "U7               1.0  \n",
       "U8               0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build user-item matrix\n",
    "user_item_df = (\n",
    "    df\n",
    "    .assign(purchased=1)\n",
    "    .pivot_table(index=\"user_id\", columns=\"item_name\", values=\"purchased\", fill_value=0)\n",
    ")\n",
    "user_item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b2bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN with k=3: Storing 6 samples.\n"
     ]
    }
   ],
   "source": [
    "# Train KNN and store results\n",
    "item_names = user_item_df.columns.tolist()\n",
    "X_items = user_item_df.values.T\n",
    "y_items = np.arange(X_items.shape[0])\n",
    "\n",
    "knn_items= KNN(k=3, distance_metric=\"cosine\")\n",
    "knn_items.fit(X_items, y_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf4c7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar to 'iPhone 15':\n",
      "[('AirPods Pro', 0.25), ('MacBook Air', 0.6464466094067263), ('Echo Dot', 0.7113248654051871)]\n",
      "\n",
      "Similar to 'Kindle Paperwhite':\n",
      "[('Echo Dot', 0.5917517095361371), ('iPad', 0.5917517095361371), ('AirPods Pro', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "# Find similar items with your KNN\n",
    "def get_similar_items_knn(target_item_name, k=3):\n",
    "    if target_item_name not in item_names:\n",
    "        raise ValueError(f\"{target_item_name} not found.\")\n",
    "    \n",
    "    # index of the item\n",
    "    item_idx = item_names.index(target_item_name)\n",
    "    item_vec = X_items[item_idx]\n",
    "\n",
    "    # query k+1 neighbors because the closest will be itself (distance 0)\n",
    "    distances, indices = knn_items.kneighbors(item_vec, k=k+1, return_distance=True)\n",
    "    distances = distances[0]\n",
    "    indices = indices[0]\n",
    "\n",
    "    # Drop itsef (distance 0, index = item_idx)\n",
    "    mask = indices != item_idx\n",
    "    neighbor_indices = indices[mask][:k]\n",
    "    neighbor_distances = distances[mask][:k]\n",
    "\n",
    "    results = []\n",
    "    for d, idx in zip(neighbor_distances, neighbor_indices):\n",
    "        results.append((item_names[idx], float(d)))\n",
    "    return results\n",
    "\n",
    "print(\"Similar to 'iPhone 15':\")\n",
    "print(get_similar_items_knn(\"iPhone 15\", k=3))\n",
    "\n",
    "print(\"\\nSimilar to 'Kindle Paperwhite':\")\n",
    "print(get_similar_items_knn(\"Kindle Paperwhite\", k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "705f7563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for U1:\n",
      "[('MacBook Air', 1.8429759183234267), ('Echo Dot', 1.168685175112245), ('Kindle Paperwhite', 0.6282386844688338)]\n",
      "\n",
      "Recommendations for U5:\n",
      "[('AirPods Pro', 1.0843425875561223), ('iPad', 0.6282386844688338), ('iPhone 15', 0.5843425875561225)]\n"
     ]
    }
   ],
   "source": [
    "# Recommend items for a user using item-KNN\n",
    "\n",
    "def recommend_for_user_knn(user_id, k_item=3, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend items for a given user based on item-to-item KNN\n",
    "    using the KNN model built on item vectors.\n",
    "    \"\"\"\n",
    "    if user_id not in user_item_df.index:\n",
    "        raise ValueError(f\"Unknown user_id: {user_id}\")\n",
    "\n",
    "    user_row = user_item_df.loc[user_id]\n",
    "    purchased_items = user_row[user_row > 0].index.tolist()\n",
    "\n",
    "    if not purchased_items:\n",
    "        return []  # cold start\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for item in purchased_items:\n",
    "        neighbors = get_similar_items_knn(item, k=k_item)\n",
    "        for neigh_item, dist in neighbors:\n",
    "            if neigh_item in purchased_items:\n",
    "                continue\n",
    "            # Convert distance -> similarity-like score (smaller dist = higher score)\n",
    "            score = 1.0 / (1.0 + dist)\n",
    "            scores[neigh_item] = scores.get(neigh_item, 0.0) + score\n",
    "\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return ranked[:top_n]\n",
    "\n",
    "\n",
    "print(\"Recommendations for U1:\")\n",
    "print(recommend_for_user_knn(\"U1\", k_item=3, top_n=5))\n",
    "\n",
    "print(\"\\nRecommendations for U5:\")\n",
    "print(recommend_for_user_knn(\"U5\", k_item=3, top_n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11826342",
   "metadata": {},
   "source": [
    "### Why do we favor cosine distance over euclidean distance?\n",
    "\n",
    "In item-to-item recommenders, cosine distance is preferred over Euclidean because it normalizes for popularity. Cosine measures similarity in the pattern of users who bought an item, regardless of how many purchases it had. Euclidean distance is dominated by vector magnitude and performs poorly in sparse, high-dimensional, binary user–item matrices. Cosine gives much more meaningful item similarity for recommender systems.\n",
    "\n",
    "1. Cosine distance measures direction, not magnitude:\n",
    "\n",
    "* Euclidean distance is sensitive to vector length:\n",
    "\t- Items purchased by many users have longer vectors\n",
    "\t- Items purchased by few users have shorter vectors\n",
    "\n",
    "* Example\n",
    "\t-\tItem A bought by 10,000 users\n",
    "\t-\tItem B bought by 200 users\n",
    "\t-\tItem C bought by 205 users, mostly overlapping with Item B\n",
    "\n",
    "Euclidean says A is closer to C than B, because A’s vector is huge.\n",
    "Cosine says B is closest to C, because they share the same pattern of buyers, even if fewer.\n",
    "\n",
    "\n",
    "2. Cosine similarity handles sparse, high-dimensional, binary data\n",
    "In sparse spaces:\n",
    "\t- Euclidean distance mostly measures “how many zeros don’t overlap”\n",
    "\t- Cosine measures angle → pattern similarity despite sparsity\n",
    "\n",
    "3. Cosine is scale-invariant \n",
    "\n",
    "Cosine similarity:\n",
    "\n",
    "$\\cos(\\theta) = \\frac{A \\cdot B}{\\|A\\| \\, \\|B\\|}$\n",
    "\n",
    "This normalizes both vectors.\n",
    "\n",
    "Meaning:\n",
    "\t•\tIf 100 people buy iPhone → long vector\n",
    "\t•\tIf 10 people buy iPhone → short vector\n",
    "\t•\tCosine will treat them as equally directional\n",
    "\n",
    "\n",
    "4. Cosine gives more intuitive “similar items” in CF\n",
    "Cosine = “same users?”\n",
    "Euclidean = “same number of users bought them?”\n",
    "\n",
    "The second is not what we want.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4ce37",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
